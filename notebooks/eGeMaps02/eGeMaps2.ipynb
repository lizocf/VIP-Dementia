{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0549e26b-a8bf-4791-8b15-cfa7383c47be",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/VIP-Dementia\n"
     ]
    }
   ],
   "source": [
    "cd /home/ec2-user/SageMaker/VIP-Dementia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a33d5250-b212-4953-8a82-e8e5fbf91ba3",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from -r requirements.txt (line 1)) (1.22.4)\n",
      "Requirement already satisfied: scikit-learn in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from -r requirements.txt (line 2)) (1.4.1.post1)\n",
      "Requirement already satisfied: json5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from -r requirements.txt (line 3)) (0.9.17)\n",
      "Collecting librosa (from -r requirements.txt (line 5))\n",
      "  Downloading librosa-0.10.1-py3-none-any.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: joblib in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from -r requirements.txt (line 6)) (1.3.2)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from -r requirements.txt (line 7)) (2.2.0)\n",
      "Collecting opensmile (from -r requirements.txt (line 8))\n",
      "  Downloading opensmile-2.5.0-py3-none-manylinux_2_17_x86_64.whl.metadata (15 kB)\n",
      "Requirement already satisfied: tqdm in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from -r requirements.txt (line 9)) (4.66.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from scikit-learn->-r requirements.txt (line 2)) (1.12.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from scikit-learn->-r requirements.txt (line 2)) (3.3.0)\n",
      "Collecting audioread>=2.1.9 (from librosa->-r requirements.txt (line 5))\n",
      "  Downloading audioread-3.0.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from librosa->-r requirements.txt (line 5)) (5.1.1)\n",
      "Requirement already satisfied: numba>=0.51.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from librosa->-r requirements.txt (line 5)) (0.59.0)\n",
      "Collecting soundfile>=0.12.1 (from librosa->-r requirements.txt (line 5))\n",
      "  Downloading soundfile-0.12.1-py2.py3-none-manylinux_2_17_x86_64.whl.metadata (14 kB)\n",
      "Collecting pooch>=1.0 (from librosa->-r requirements.txt (line 5))\n",
      "  Downloading pooch-1.8.1-py3-none-any.whl.metadata (9.5 kB)\n",
      "Collecting soxr>=0.3.2 (from librosa->-r requirements.txt (line 5))\n",
      "  Downloading soxr-0.3.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from librosa->-r requirements.txt (line 5)) (4.9.0)\n",
      "Requirement already satisfied: lazy-loader>=0.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from librosa->-r requirements.txt (line 5)) (0.3)\n",
      "Requirement already satisfied: msgpack>=1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from librosa->-r requirements.txt (line 5)) (1.0.7)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas->-r requirements.txt (line 7)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas->-r requirements.txt (line 7)) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas->-r requirements.txt (line 7)) (2024.1)\n",
      "Collecting audobject>=0.6.1 (from opensmile->-r requirements.txt (line 8))\n",
      "  Downloading audobject-0.7.11-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting audinterface>=0.7.0 (from opensmile->-r requirements.txt (line 8))\n",
      "  Downloading audinterface-1.2.1-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting audeer>=1.18.0 (from audinterface>=0.7.0->opensmile->-r requirements.txt (line 8))\n",
      "  Downloading audeer-2.0.0-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting audformat<2.0.0,>=1.0.1 (from audinterface>=0.7.0->opensmile->-r requirements.txt (line 8))\n",
      "  Downloading audformat-1.1.2-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting audiofile>=1.3.0 (from audinterface>=0.7.0->opensmile->-r requirements.txt (line 8))\n",
      "  Downloading audiofile-1.4.0-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting audmath>=1.3.0 (from audinterface>=0.7.0->opensmile->-r requirements.txt (line 8))\n",
      "  Downloading audmath-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting audresample<2.0.0,>=1.1.0 (from audinterface>=0.7.0->opensmile->-r requirements.txt (line 8))\n",
      "  Downloading audresample-1.3.3-py3-none-manylinux_2_17_x86_64.whl.metadata (4.4 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from audobject>=0.6.1->opensmile->-r requirements.txt (line 8)) (6.11.0)\n",
      "Collecting oyaml (from audobject>=0.6.1->opensmile->-r requirements.txt (line 8))\n",
      "  Downloading oyaml-1.0-py2.py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: packaging in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from audobject>=0.6.1->opensmile->-r requirements.txt (line 8)) (21.3)\n",
      "Requirement already satisfied: llvmlite<0.43,>=0.42.0dev0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from numba>=0.51.0->librosa->-r requirements.txt (line 5)) (0.42.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pooch>=1.0->librosa->-r requirements.txt (line 5)) (4.2.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pooch>=1.0->librosa->-r requirements.txt (line 5)) (2.31.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->-r requirements.txt (line 7)) (1.16.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from soundfile>=0.12.1->librosa->-r requirements.txt (line 5)) (1.16.0)\n",
      "Collecting iso-639 (from audformat<2.0.0,>=1.0.1->audinterface>=0.7.0->opensmile->-r requirements.txt (line 8))\n",
      "  Downloading iso-639-0.4.5.tar.gz (167 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.4/167.4 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting iso3166 (from audformat<2.0.0,>=1.0.1->audinterface>=0.7.0->opensmile->-r requirements.txt (line 8))\n",
      "  Downloading iso3166-2.1.1-py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: pyyaml>=5.4.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from audformat<2.0.0,>=1.0.1->audinterface>=0.7.0->opensmile->-r requirements.txt (line 8)) (6.0.1)\n",
      "Requirement already satisfied: pycparser in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa->-r requirements.txt (line 5)) (2.21)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from importlib-metadata>=4.8.0->audobject>=0.6.1->opensmile->-r requirements.txt (line 8)) (3.17.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from packaging->audobject>=0.6.1->opensmile->-r requirements.txt (line 8)) (3.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.0->librosa->-r requirements.txt (line 5)) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.0->librosa->-r requirements.txt (line 5)) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.0->librosa->-r requirements.txt (line 5)) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.0->librosa->-r requirements.txt (line 5)) (2024.2.2)\n",
      "Downloading librosa-0.10.1-py3-none-any.whl (253 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.7/253.7 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opensmile-2.5.0-py3-none-manylinux_2_17_x86_64.whl (996 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m996.2/996.2 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading audinterface-1.2.1-py3-none-any.whl (66 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading audioread-3.0.1-py3-none-any.whl (23 kB)\n",
      "Downloading audobject-0.7.11-py3-none-any.whl (43 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pooch-1.8.1-py3-none-any.whl (62 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.0/63.0 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading soundfile-0.12.1-py2.py3-none-manylinux_2_17_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading soxr-0.3.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading audeer-2.0.0-py3-none-any.whl (39 kB)\n",
      "Downloading audformat-1.1.2-py3-none-any.whl (140 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.9/140.9 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading audiofile-1.4.0-py3-none-any.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading audmath-1.4.0-py3-none-any.whl (23 kB)\n",
      "Downloading audresample-1.3.3-py3-none-manylinux_2_17_x86_64.whl (138 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.4/138.4 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading oyaml-1.0-py2.py3-none-any.whl (3.0 kB)\n",
      "Downloading iso3166-2.1.1-py3-none-any.whl (9.8 kB)\n",
      "Building wheels for collected packages: iso-639\n",
      "  Building wheel for iso-639 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for iso-639: filename=iso_639-0.4.5-py3-none-any.whl size=168840 sha256=1e730fde9013b94b14ef7af3551f76874dcc1e9ac1829aebd8ccd1c20cbeb96f\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/d8/78/cc/5478ca3b1c3f602eae6f8cdbd78f909c0a0bfa0bbcb5c7771f\n",
      "Successfully built iso-639\n",
      "Installing collected packages: iso-639, soxr, oyaml, iso3166, audresample, audmath, audioread, audeer, soundfile, pooch, audobject, librosa, audiofile, audformat, audinterface, opensmile\n",
      "Successfully installed audeer-2.0.0 audformat-1.1.2 audinterface-1.2.1 audiofile-1.4.0 audioread-3.0.1 audmath-1.4.0 audobject-0.7.11 audresample-1.3.3 iso-639-0.4.5 iso3166-2.1.1 librosa-0.10.1 opensmile-2.5.0 oyaml-1.0 pooch-1.8.1 soundfile-0.12.1 soxr-0.3.7\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0066d296-0ed4-421d-a080-ca1f632d8767",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/VIP-Dementia/audio_processing\n"
     ]
    }
   ],
   "source": [
    "cd /home/ec2-user/SageMaker/VIP-Dementia/audio_processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8428e46-8dc5-4129-93ba-cfda90f669dd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total AD files: 87\n",
      "Total CN files: 79\n",
      "Total files: 166\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Assuming the directory setup remains unchanged\n",
    "HOME_DIRECTORY = os.path.expanduser(\"~/SageMaker/VIP-Dementia\")\n",
    "RAW_DATA_DIR = os.path.join(HOME_DIRECTORY, 'data/raw')\n",
    "\n",
    "# Calculate total number of .wav files in each partition (AD and CN)\n",
    "total_ad_files = len([name for name in os.listdir(os.path.join(RAW_DATA_DIR, 'audio', 'ad')) if name.endswith('.wav')])\n",
    "total_cn_files = len([name for name in os.listdir(os.path.join(RAW_DATA_DIR, 'audio', 'cn')) if name.endswith('.wav')])\n",
    "\n",
    "print(\"Total AD files:\", total_ad_files)\n",
    "print(\"Total CN files:\", total_cn_files)\n",
    "print(\"Total files:\", total_ad_files + total_cn_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cbf4bffa-95d6-4f2d-9d0f-b142d4c29c9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import opensmile\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Assuming the directory setup remains unchanged\n",
    "HOME_DIRECTORY = os.path.expanduser(\"~/SageMaker/VIP-Dementia\")\n",
    "RAW_DATA_DIR = os.path.join(HOME_DIRECTORY, 'data/raw')\n",
    "PROCESSED_DATA_DIR = os.path.join(HOME_DIRECTORY, 'data/processed')\n",
    "FEATURES_DIR = os.path.join(PROCESSED_DATA_DIR, 'features')\n",
    "LABELS_DIR = os.path.join(PROCESSED_DATA_DIR, 'labels')\n",
    "\n",
    "# Label mapping for binary classification\n",
    "label_dict = {'CN': 0, 'AD': 1}\n",
    "\n",
    "def get_features(audio_path):\n",
    "    \"\"\"\n",
    "    Extract features for the entire audio file.\n",
    "\n",
    "    :param audio_path: Path to the audio file.\n",
    "    :return: DataFrame containing extracted features.\n",
    "    \"\"\"\n",
    "    smile = opensmile.Smile(\n",
    "        feature_set=opensmile.FeatureSet.eGeMAPSv02,\n",
    "        feature_level=opensmile.FeatureLevel.Functionals,\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        # Load the entire audio file\n",
    "        y, sr = librosa.load(audio_path, sr=None)\n",
    "        # Extract features using OpenSMILE\n",
    "        features_df = smile.process_signal(y, sr)\n",
    "        return features_df\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {audio_path}: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def load_audio_data():\n",
    "    X, y = [], []\n",
    "    partitions = ['ad', 'cn']\n",
    "    total_ad_files = len([name for name in os.listdir(os.path.join(RAW_DATA_DIR, 'audio', 'ad')) if name.endswith('.wav')])\n",
    "    total_cn_files = len([name for name in os.listdir(os.path.join(RAW_DATA_DIR, 'audio', 'cn')) if name.endswith('.wav')])\n",
    "    total_files = total_ad_files + total_cn_files\n",
    "    processed_count = 0\n",
    "\n",
    "    for partition in partitions:\n",
    "        audio_dir = os.path.join(RAW_DATA_DIR, 'audio', partition)\n",
    "        audio_files = [os.path.join(audio_dir, f) for f in os.listdir(audio_dir) if f.endswith('.wav')]\n",
    "        \n",
    "        # Using tqdm to display progress\n",
    "        with tqdm(total=len(audio_files), desc=f\"Processing {partition.upper()} files\") as pbar:\n",
    "            for audio_path in audio_files:\n",
    "                features_df = get_features(audio_path)\n",
    "                if not features_df.empty:\n",
    "                    X.append(features_df)\n",
    "                    y.append(label_dict[partition.upper()])\n",
    "                processed_count += 1\n",
    "                pbar.update(1)\n",
    "\n",
    "    print(f\"\\nFinished loading audio data. Successfully processed {processed_count} audio files out of {total_files} files.\")\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "195772cc-a17e-4a84-a61f-2ff63e98f548",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing AD files: 100%|██████████| 87/87 [13:30<00:00,  9.32s/it]\n",
      "Processing CN files: 100%|██████████| 79/79 [08:50<00:00,  6.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finished loading audio data. Successfully processed 166 audio files out of 166 files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "X, y = load_audio_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe672d8d-5655-4287-bca8-de80f0885ff5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Audio samples represented: 166\n",
      "Numerical features extracted per sample: 88\n",
      "Unique labels in dataset: [1 0]\n",
      "Training set size: 132\n",
      "Validation set size: 17\n",
      "Test set size: 17\n",
      "Saved X_train.npy to /home/ec2-user/SageMaker/VIP-Dementia/data/processed\n",
      "Saved X_valid.npy to /home/ec2-user/SageMaker/VIP-Dementia/data/processed\n",
      "Saved X_test.npy to /home/ec2-user/SageMaker/VIP-Dementia/data/processed\n",
      "Saved y_train.npy to /home/ec2-user/SageMaker/VIP-Dementia/data/processed\n",
      "Saved y_valid.npy to /home/ec2-user/SageMaker/VIP-Dementia/data/processed\n",
      "Saved y_test.npy to /home/ec2-user/SageMaker/VIP-Dementia/data/processed\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "features_df = pd.concat(X, ignore_index=True)\n",
    "labels_series = pd.Series(y)\n",
    "print(f'\\nAudio samples represented: {len(X)}')  # Total number of audio files processed\n",
    "print(f'Numerical features extracted per sample: {features_df.shape[1]}')\n",
    "print(f'Unique labels in dataset: {labels_series.unique()}')\n",
    "\n",
    "# Display the first few rows of the features DataFrame to check the data\n",
    "features_df.head()\n",
    "\n",
    "# Assuming 'features_df' and 'labels_series' are already defined and contain all your data\n",
    "X = features_df\n",
    "y = labels_series\n",
    "\n",
    "# First, split into a training and a temp set (combining validation and test) with an 80/20 split\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Then split the temp set equally into validation and test sets\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n",
    "\n",
    "# Display sizes of the datasets\n",
    "print(f\"Training set size: {X_train.shape[0]}\")\n",
    "print(f\"Validation set size: {X_valid.shape[0]}\")\n",
    "print(f\"Test set size: {X_test.shape[0]}\")\n",
    "\n",
    "# Specify the directory where you want to save the files\n",
    "save_dir = PROCESSED_DATA_DIR\n",
    "\n",
    "# Function to save datasets\n",
    "def save_dataset(filename, dataset):\n",
    "    path = os.path.join(save_dir, filename)\n",
    "    np.save(path, dataset)\n",
    "    print(f\"Saved {filename} to {save_dir}\")\n",
    "\n",
    "# Saving each dataset\n",
    "save_dataset('X_train.npy', X_train)\n",
    "save_dataset('X_valid.npy', X_valid)\n",
    "save_dataset('X_test.npy', X_test)\n",
    "save_dataset('y_train.npy', y_train)\n",
    "save_dataset('y_valid.npy', y_valid)\n",
    "save_dataset('y_test.npy', y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b3c259aa-00cc-415e-81d0-473f2452f507",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded X_train: (132, 88), y_train: (132,)\n",
      "Loaded X_valid: (17, 88), y_valid: (17,)\n",
      "Loaded X_test: (17, 88), y_test: (17,)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Correct directory path setup\n",
    "HOME_DIRECTORY = os.path.expanduser(\"~/SageMaker/VIP-Dementia\")\n",
    "SPLIT_DATA_DIR = os.path.join(HOME_DIRECTORY, 'data/processed')\n",
    "\n",
    "# Function to load datasets\n",
    "def load_dataset(filename):\n",
    "    path = os.path.join(SPLIT_DATA_DIR, filename)\n",
    "    if os.path.exists(path):\n",
    "        return np.load(path, allow_pickle=True)\n",
    "    else:\n",
    "        print(f\"File {filename} not found in {SPLIT_DATA_DIR}. Please check the directory and try again.\")\n",
    "        return None\n",
    "\n",
    "# Loading each dataset\n",
    "X_train = load_dataset('X_train.npy')\n",
    "X_valid = load_dataset('X_valid.npy')\n",
    "X_test = load_dataset('X_test.npy')\n",
    "y_train = load_dataset('y_train.npy')\n",
    "y_valid = load_dataset('y_valid.npy')\n",
    "y_test = load_dataset('y_test.npy')\n",
    "\n",
    "# Verifying the shapes of the loaded datasets (if they were successfully loaded)\n",
    "if X_train is not None and y_train is not None:\n",
    "    print(f\"Loaded X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
    "if X_valid is not None and y_valid is not None:\n",
    "    print(f\"Loaded X_valid: {X_valid.shape}, y_valid: {y_valid.shape}\")\n",
    "if X_test is not None and y_test is not None:\n",
    "    print(f\"Loaded X_test: {X_test.shape}, y_test: {y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fbf27201-ec53-428b-8f0a-bdedaadaec61",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "classification_models = [\n",
    "    KNeighborsClassifier(),#(3),\n",
    "    SVC(kernel='linear'),#, C=0.025),\n",
    "    SVC(kernel='rbf'),\n",
    "    DecisionTreeClassifier(),#max_depth=5),\n",
    "    RandomForestClassifier(),#max_depth=5, n_estimators=10, max_features=1),\n",
    "    AdaBoostClassifier(),\n",
    "    GaussianNB(),\n",
    "    QuadraticDiscriminantAnalysis()]\n",
    "\n",
    "scores = []\n",
    "for model in classification_models:\n",
    "    try:\n",
    "        model.fit(X_train, y_train)\n",
    "        score = model.score(X_test, y_test)\n",
    "        model_name = type(model).__name__\n",
    "        if isinstance(model, SVC) and model.kernel == 'rbf':\n",
    "            model_name += ' RBF kernel'\n",
    "        scores.append((model_name, f'{100*score:.2f}%'))\n",
    "    except ValueError as e:\n",
    "        print(f\"Error training {type(model).__name__}: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "02d08e37-5560-46b9-92de-701ce4f0fe41",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Accuracy Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>70.59%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>70.59%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>70.59%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>70.59%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVC</td>\n",
       "      <td>64.71%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>64.71%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVC RBF kernel</td>\n",
       "      <td>52.94%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>47.06%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Classifier Accuracy Score\n",
       "3         DecisionTreeClassifier         70.59%\n",
       "4         RandomForestClassifier         70.59%\n",
       "5             AdaBoostClassifier         70.59%\n",
       "7  QuadraticDiscriminantAnalysis         70.59%\n",
       "1                            SVC         64.71%\n",
       "6                     GaussianNB         64.71%\n",
       "2                 SVC RBF kernel         52.94%\n",
       "0           KNeighborsClassifier         47.06%"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make it pretty\n",
    "scores_df = pd.DataFrame(scores,columns=['Classifier','Accuracy Score'])\n",
    "scores_df.sort_values(by='Accuracy Score',axis=0,ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
