{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0508df8-bd9d-4ecf-b5d3-f03ff7afe47b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/VIP-Dementia/audio_processing\n"
     ]
    }
   ],
   "source": [
    "cd /home/ec2-user/SageMaker/VIP-Dementia/audio_processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ab28e2b-53d3-404f-82a4-babc86148367",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import opensmile\n",
    "from tqdm import tqdm\n",
    "\n",
    "HOME_DIRECTORY = os.path.expanduser(\"~/SageMaker/VIP-Dementia\")\n",
    "RAW_DATA_DIR = os.path.join(HOME_DIRECTORY, 'data/raw')\n",
    "PROCESSED_DATA_DIR = os.path.join(HOME_DIRECTORY, 'data/processed')\n",
    "FEATURES_DIR = os.path.join(PROCESSED_DATA_DIR, 'features')\n",
    "LABELS_DIR = os.path.join(PROCESSED_DATA_DIR, 'labels')\n",
    "\n",
    "# Label mapping for binary classification\n",
    "label_dict = {'CN': 0, 'AD': 1}\n",
    "\n",
    "def get_features(audio_path, sample_rate=41000):\n",
    "    \"\"\"\n",
    "    Extract features for the entire audio file at a specified sampling rate.\n",
    "\n",
    "    :param audio_path: Path to the audio file.\n",
    "    :param sample_rate: Desired sampling rate (in Hz).\n",
    "    :return: DataFrame containing extracted features.\n",
    "    \"\"\"\n",
    "    smile = opensmile.Smile(\n",
    "        feature_set=opensmile.FeatureSet.eGeMAPSv02,\n",
    "        feature_level=opensmile.FeatureLevel.Functionals,\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        # Load the entire audio file at the specified sampling rate (window size)\n",
    "        y, sr = librosa.load(audio_path, sr=sample_rate)\n",
    "        features_df = smile.process_signal(y, sr)\n",
    "        return features_df\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {audio_path}: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def load_audio_data(sample_rate=41000):\n",
    "    X, y = [], []\n",
    "    partitions = ['ad', 'cn']\n",
    "    for partition in partitions:\n",
    "        audio_dir = os.path.join(RAW_DATA_DIR, 'audio', partition)\n",
    "        audio_files = [os.path.join(audio_dir, f) for f in os.listdir(audio_dir) if f.endswith('.wav')]\n",
    "        with tqdm(total=len(audio_files), desc=f\"Processing {partition.upper()} files\") as pbar:\n",
    "            for audio_path in audio_files:\n",
    "                df = get_features(audio_path, sample_rate)\n",
    "                if not df.empty:\n",
    "                    X.append(df)\n",
    "                    y.append(label_dict[partition.upper()])\n",
    "                pbar.update(1)\n",
    "    print(f\"Finished processing {len(X)} files. Type of X: {type(X)}\")\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd9f8477-7c46-43bd-9e16-41dbe8cb51c8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing AD files: 100%|██████████| 87/87 [10:32<00:00,  7.28s/it]\n",
      "Processing CN files: 100%|██████████| 79/79 [07:25<00:00,  5.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing 166 files. Type of X: <class 'list'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "X, y = load_audio_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df751dca-afc0-4a59-b298-bdc3310bf5f8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Audio samples represented: 166\n",
      "Numerical features extracted per sample: 88\n",
      "Unique labels in dataset: [1 0]\n",
      "Training set size: 132\n",
      "Validation set size: 17\n",
      "Test set size: 17\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Tests to make sure data was split correctly\n",
    "features_df = pd.concat(X, ignore_index=True)\n",
    "labels_series = pd.Series(y)\n",
    "print(f'\\nAudio samples represented: {len(X)}')\n",
    "print(f'Numerical features extracted per sample: {features_df.shape[1]}')\n",
    "print(f'Unique labels in dataset: {labels_series.unique()}')\n",
    "\n",
    "X = features_df\n",
    "y = labels_series\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n",
    "\n",
    "# Display sizes of the datasets\n",
    "print(f\"Training set size: {X_train.shape[0]}\")\n",
    "print(f\"Validation set size: {X_valid.shape[0]}\")\n",
    "print(f\"Test set size: {X_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "374aca46-5aa0-4e1d-86b5-eae89fc10494",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved X_train.npy to /home/ec2-user/SageMaker/VIP-Dementia/data/processed\n",
      "Saved X_valid.npy to /home/ec2-user/SageMaker/VIP-Dementia/data/processed\n",
      "Saved X_test.npy to /home/ec2-user/SageMaker/VIP-Dementia/data/processed\n",
      "Saved y_train.npy to /home/ec2-user/SageMaker/VIP-Dementia/data/processed\n",
      "Saved y_valid.npy to /home/ec2-user/SageMaker/VIP-Dementia/data/processed\n",
      "Saved y_test.npy to /home/ec2-user/SageMaker/VIP-Dementia/data/processed\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Directory to save files\n",
    "HOME_DIRECTORY = os.path.expanduser(\"~/SageMaker/VIP-Dementia\")\n",
    "save_dir = os.path.join(HOME_DIRECTORY, 'data/processed')\n",
    "\n",
    "# Function to save datasets\n",
    "def save_dataset(filename, dataset):\n",
    "    path = os.path.join(save_dir, filename)\n",
    "    np.save(path, dataset)\n",
    "    print(f\"Saved {filename} to {save_dir}\")\n",
    "\n",
    "# Saving each dataset\n",
    "save_dataset('X_train.npy', X_train)\n",
    "save_dataset('X_valid.npy', X_valid)\n",
    "save_dataset('X_test.npy', X_test)\n",
    "save_dataset('y_train.npy', y_train)\n",
    "save_dataset('y_valid.npy', y_valid)\n",
    "save_dataset('y_test.npy', y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24cc7e50-934f-4b65-813a-bd34cf0bc463",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded X_train: (132, 88), y_train: (132,)\n",
      "Loaded X_valid: (17, 88), y_valid: (17,)\n",
      "Loaded X_test: (17, 88), y_test: (17,)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Tests to make sure data was saved correctly\n",
    "HOME_DIRECTORY = os.path.expanduser(\"~/SageMaker/VIP-Dementia\")\n",
    "save_dir = os.path.join(HOME_DIRECTORY, 'data/processed/eGeMAPS/44100')\n",
    "SPLIT_DATA_DIR = save_dir\n",
    "\n",
    "# Function to load datasets\n",
    "def load_dataset(filename):\n",
    "    path = os.path.join(SPLIT_DATA_DIR, filename)\n",
    "    if os.path.exists(path):\n",
    "        return np.load(path, allow_pickle=True)\n",
    "    else:\n",
    "        print(f\"File {filename} not found in {SPLIT_DATA_DIR}. Please check the directory and try again.\")\n",
    "        return None\n",
    "\n",
    "# Loading each dataset\n",
    "X_train = load_dataset('X_train.npy')\n",
    "X_valid = load_dataset('X_valid.npy')\n",
    "X_test = load_dataset('X_test.npy')\n",
    "y_train = load_dataset('y_train.npy')\n",
    "y_valid = load_dataset('y_valid.npy')\n",
    "y_test = load_dataset('y_test.npy')\n",
    "\n",
    "# Verifying the shapes of the loaded datasets\n",
    "if X_train is not None and y_train is not None:\n",
    "    print(f\"Loaded X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
    "if X_valid is not None and y_valid is not None:\n",
    "    print(f\"Loaded X_valid: {X_valid.shape}, y_valid: {y_valid.shape}\")\n",
    "if X_test is not None and y_test is not None:\n",
    "    print(f\"Loaded X_test: {X_test.shape}, y_test: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d2cd40f-8c44-4e03-8c93-5b5f03364f4f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "classification_models = [\n",
    "    KNeighborsClassifier(),\n",
    "    SVC(kernel='linear'),\n",
    "    SVC(kernel='rbf'),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    AdaBoostClassifier(),\n",
    "    GaussianNB(),\n",
    "    QuadraticDiscriminantAnalysis()\n",
    "]\n",
    "\n",
    "scores = []\n",
    "for model in classification_models:\n",
    "    try:\n",
    "        model.fit(X_train, y_train)\n",
    "        score = model.score(X_test, y_test)\n",
    "        model_name = type(model).__name__\n",
    "        if isinstance(model, SVC) and model.kernel == 'rbf':\n",
    "            model_name += ' RBF kernel'\n",
    "        scores.append((model_name, f'{100*score:.2f}%'))\n",
    "    except ValueError as e:\n",
    "        print(f\"Error training {type(model).__name__}: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d48a1aa-4347-4d31-991c-e92d14ac8f2a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Accuracy Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>76.47%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>70.59%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>64.71%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>64.71%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVC</td>\n",
       "      <td>58.82%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>58.82%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVC RBF kernel</td>\n",
       "      <td>52.94%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>52.94%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Classifier Accuracy Score\n",
       "4         RandomForestClassifier         76.47%\n",
       "6                     GaussianNB         70.59%\n",
       "0           KNeighborsClassifier         64.71%\n",
       "5             AdaBoostClassifier         64.71%\n",
       "1                            SVC         58.82%\n",
       "3         DecisionTreeClassifier         58.82%\n",
       "2                 SVC RBF kernel         52.94%\n",
       "7  QuadraticDiscriminantAnalysis         52.94%"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "scores_df = pd.DataFrame(scores,columns=['Classifier','Accuracy Score'])\n",
    "scores_df.sort_values(by='Accuracy Score',axis=0,ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
