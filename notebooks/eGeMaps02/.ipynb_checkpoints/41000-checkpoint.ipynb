{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0508df8-bd9d-4ecf-b5d3-f03ff7afe47b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/VIP-Dementia/audio_processing\n"
     ]
    }
   ],
   "source": [
    "cd /home/ec2-user/SageMaker/VIP-Dementia/audio_processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ab28e2b-53d3-404f-82a4-babc86148367",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import opensmile\n",
    "from tqdm import tqdm\n",
    "\n",
    "HOME_DIRECTORY = os.path.expanduser(\"~/SageMaker/VIP-Dementia\")\n",
    "RAW_DATA_DIR = os.path.join(HOME_DIRECTORY, 'data/raw')\n",
    "PROCESSED_DATA_DIR = os.path.join(HOME_DIRECTORY, 'data/processed')\n",
    "FEATURES_DIR = os.path.join(PROCESSED_DATA_DIR, 'features')\n",
    "LABELS_DIR = os.path.join(PROCESSED_DATA_DIR, 'labels')\n",
    "\n",
    "# Label mapping for binary classification\n",
    "label_dict = {'CN': 0, 'AD': 1}\n",
    "\n",
    "def get_features(audio_path, sample_rate=41000):\n",
    "    \"\"\"\n",
    "    Extract features for the entire audio file at a specified sampling rate.\n",
    "\n",
    "    :param audio_path: Path to the audio file.\n",
    "    :param sample_rate: Desired sampling rate (in Hz).\n",
    "    :return: DataFrame containing extracted features.\n",
    "    \"\"\"\n",
    "    smile = opensmile.Smile(\n",
    "        feature_set=opensmile.FeatureSet.eGeMAPSv02,\n",
    "        feature_level=opensmile.FeatureLevel.Functionals,\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        # Load the entire audio file at the specified sampling rate (window size)\n",
    "        y, sr = librosa.load(audio_path, sr=sample_rate)\n",
    "        features_df = smile.process_signal(y, sr)\n",
    "        return features_df\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {audio_path}: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def load_audio_data(sample_rate=41000):\n",
    "    X, y = [], []\n",
    "    partitions = ['ad', 'cn']\n",
    "    for partition in partitions:\n",
    "        audio_dir = os.path.join(RAW_DATA_DIR, 'audio', partition)\n",
    "        audio_files = [os.path.join(audio_dir, f) for f in os.listdir(audio_dir) if f.endswith('.wav')]\n",
    "        with tqdm(total=len(audio_files), desc=f\"Processing {partition.upper()} files\") as pbar:\n",
    "            for audio_path in audio_files:\n",
    "                df = get_features(audio_path, sample_rate)\n",
    "                if not df.empty:\n",
    "                    X.append(df)\n",
    "                    y.append(label_dict[partition.upper()])\n",
    "                pbar.update(1)\n",
    "    print(f\"Finished processing {len(X)} files. Type of X: {type(X)}\")\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd9f8477-7c46-43bd-9e16-41dbe8cb51c8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing AD files: 100%|██████████| 87/87 [10:32<00:00,  7.28s/it]\n",
      "Processing CN files: 100%|██████████| 79/79 [07:25<00:00,  5.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing 166 files. Type of X: <class 'list'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "X, y = load_audio_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df751dca-afc0-4a59-b298-bdc3310bf5f8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Audio samples represented: 166\n",
      "Numerical features extracted per sample: 88\n",
      "Unique labels in dataset: [1 0]\n",
      "Training set size: 132\n",
      "Validation set size: 17\n",
      "Test set size: 17\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Tests to make sure data was split correctly\n",
    "features_df = pd.concat(X, ignore_index=True)\n",
    "labels_series = pd.Series(y)\n",
    "print(f'\\nAudio samples represented: {len(X)}')\n",
    "print(f'Numerical features extracted per sample: {features_df.shape[1]}')\n",
    "print(f'Unique labels in dataset: {labels_series.unique()}')\n",
    "\n",
    "X = features_df\n",
    "y = labels_series\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n",
    "\n",
    "# Display sizes of the datasets\n",
    "print(f\"Training set size: {X_train.shape[0]}\")\n",
    "print(f\"Validation set size: {X_valid.shape[0]}\")\n",
    "print(f\"Test set size: {X_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "374aca46-5aa0-4e1d-86b5-eae89fc10494",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved X_train.npy to /home/ec2-user/SageMaker/VIP-Dementia/data/processed\n",
      "Saved X_valid.npy to /home/ec2-user/SageMaker/VIP-Dementia/data/processed\n",
      "Saved X_test.npy to /home/ec2-user/SageMaker/VIP-Dementia/data/processed\n",
      "Saved y_train.npy to /home/ec2-user/SageMaker/VIP-Dementia/data/processed\n",
      "Saved y_valid.npy to /home/ec2-user/SageMaker/VIP-Dementia/data/processed\n",
      "Saved y_test.npy to /home/ec2-user/SageMaker/VIP-Dementia/data/processed\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Directory to save files\n",
    "HOME_DIRECTORY = os.path.expanduser(\"~/SageMaker/VIP-Dementia\")\n",
    "save_dir = os.path.join(HOME_DIRECTORY, 'data/processed')\n",
    "\n",
    "# Function to save datasets\n",
    "def save_dataset(filename, dataset):\n",
    "    path = os.path.join(save_dir, filename)\n",
    "    np.save(path, dataset)\n",
    "    print(f\"Saved {filename} to {save_dir}\")\n",
    "\n",
    "# Saving each dataset\n",
    "save_dataset('X_train.npy', X_train)\n",
    "save_dataset('X_valid.npy', X_valid)\n",
    "save_dataset('X_test.npy', X_test)\n",
    "save_dataset('y_train.npy', y_train)\n",
    "save_dataset('y_valid.npy', y_valid)\n",
    "save_dataset('y_test.npy', y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24cc7e50-934f-4b65-813a-bd34cf0bc463",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Tests to make sure data was saved correctly\n",
    "HOME_DIRECTORY = os.path.expanduser(\"~/SageMaker/VIP-Dementia\")\n",
    "save_dir = os.path.join(HOME_DIRECTORY, 'data/processed/eGeMAPS/44100')\n",
    "SPLIT_DATA_DIR = save_dir\n",
    "\n",
    "# Function to load datasets\n",
    "def load_dataset(filename):\n",
    "    path = os.path.join(SPLIT_DATA_DIR, filename)\n",
    "    if os.path.exists(path):\n",
    "        return np.load(path, allow_pickle=True)\n",
    "    else:\n",
    "        print(f\"File {filename} not found in {SPLIT_DATA_DIR}. Please check the directory and try again.\")\n",
    "        return None\n",
    "\n",
    "# Loading each dataset\n",
    "X_train = load_dataset('X_train.npy')\n",
    "X_valid = load_dataset('X_valid.npy')\n",
    "X_test = load_dataset('X_test.npy')\n",
    "y_train = load_dataset('y_train.npy')\n",
    "y_valid = load_dataset('y_valid.npy')\n",
    "y_test = load_dataset('y_test.npy')\n",
    "\n",
    "# Verifying the shapes of the loaded datasets\n",
    "if X_train is not None and y_train is not None:\n",
    "    print(f\"Loaded X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
    "if X_valid is not None and y_valid is not None:\n",
    "    print(f\"Loaded X_valid: {X_valid.shape}, y_valid: {y_valid.shape}\")\n",
    "if X_test is not None and y_test is not None:\n",
    "    print(f\"Loaded X_test: {X_test.shape}, y_test: {y_test.shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
